import json
import os
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
from datetime import datetime
import re
from typing import List, Dict, Tuple

# í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


class AdvancedSentimentAnalyzer:
    """KNU í•œêµ­ì–´ ê°ì„±ì‚¬ì „ ê¸°ë°˜ ê°ì„± ë¶„ì„ê¸°"""

    def __init__(self, senti_dict_path="SentiWord_info.json"):
        self.sentiment_dict = {}

        # ê°ì„±ì‚¬ì „ íŒŒì¼ ê²½ë¡œ ì°¾ê¸° (ìœ ì—°í•œ ê²½ë¡œ íƒìƒ‰)
        script_dir = os.path.dirname(os.path.abspath(__file__))

        # 1ìˆœìœ„: í˜„ì¬ ë””ë ‰í† ë¦¬
        # 2ìˆœìœ„: ../script/ ë””ë ‰í† ë¦¬
        possible_paths = [
            os.path.join(script_dir, senti_dict_path),
            os.path.join(os.path.dirname(script_dir), "script", senti_dict_path)
        ]

        full_path = None
        for path in possible_paths:
            if os.path.exists(path):
                full_path = path
                break

        if full_path is None:
            full_path = possible_paths[0]  # ê¸°ë³¸ê°’

        self.load_sentiment_dict(full_path)

        # ê´‘ê³  ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ ì‚¬ì „ (í™•ì¥)
        self.style_keywords = {
            'ìœ ë¨¸í˜•': ['ã…‹', 'ã…', 'ì›ƒ', 'ì¬ë¯¸', 'ìœ ë¨¸', 'ìš°ìŠµ', 'ê¹”ê¹”', 'í•˜í•˜'],
            'ê°ì„±í˜•': ['ë§ˆìŒ', 'ì‚¬ë‘', 'í–‰ë³µ', 'ë”°ëœ»', 'ì†Œì¤‘', 'ê°ë™', 'ì¶”ì–µ', 'í•¨ê»˜', 'ê°€ì¡±', 'ì¼ìƒ', 'ìˆœê°„'],
            'ì •ë³´í˜•': ['ìƒˆë¡œìš´', 'ìµœì´ˆ', 'ê¸°ìˆ ', 'í˜ì‹ ', 'íŠ¹í—ˆ', 'ê°œë°œ', 'ì„±ë¶„', 'íš¨ê³¼', 'ê³¼í•™'],
            'ê¸´ê¸‰í˜•': ['ì§€ê¸ˆ', 'ì˜¤ëŠ˜', 'í•œì •', 'ë§ˆì§€ë§‰', 'ì„œë‘˜', 'ë¹¨ë¦¬', 'ê³§', 'ì¦‰ì‹œ', 'ë°”ë¡œ'],
            'í”„ë¦¬ë¯¸ì—„í˜•': ['í”„ë¦¬ë¯¸ì—„', 'ëŸ­ì…”ë¦¬', 'ê³ ê¸‰', 'ëª…í’ˆ', 'ìµœê³ ê¸‰', 'íŠ¹ë³„', 'í•œì •íŒ', 'ê²©'],
            'ì‹¤ìš©í˜•': ['í¸ë¦¬', 'ê°„í¸', 'ì‹¤ìš©', 'ìœ ìš©', 'íš¨ìœ¨', 'ì ˆì•½', 'ì•Œëœ¸', 'ê°€ì„±ë¹„', 'ì‰½', 'ë¹ ë¥¸'],
            'ë„ì „í˜•': ['ë„ì „', 'ê·¹ë³µ', 'ì„±ì·¨', 'ê¿ˆ', 'ëª©í‘œ', 'ì—´ì •', 'ì„±ê³µ', 'ì´ë£¨', 'ì‹œì‘', 'ë³€í™”'],
            'ì–¸ì–´ìœ í¬í˜•': ['ì¹œêµ¬', 'íŒ€', 'êµ­ë£°', 'ì¼€ë¯¸', 'í†µì—­'],
            'ê±´ê°•ì›°ë¹™í˜•': ['ê±´ê°•', 'í”¼ë¡œ', 'ìƒì²˜', 'í†µì¦', 'ì˜ì–‘', 'ì¼€ì–´'],
            'ë¼ì´í”„í˜•': ['ìŠ¤íƒ€ì¼', 'ì‚¶', 'ìƒí™œ', 'ë””ìì¸', 'ì·¨í–¥', 'ë‚˜ë‹µ', 'ë§¤ì¼'],
            'í˜ì‹ ê¸°ìˆ í˜•': ['AI', 'í˜ì‹ ', 'ë¯¸ë˜', 'ì„±ì¥', 'ë°œì „', 'ì§„í™”', 'ìŠ¤ë§ˆíŠ¸']
        }

        # ì‚°ì—…êµ° í‚¤ì›Œë“œ ì‚¬ì „
        self.industry_keywords = {
            'ê¸°ìˆ IT': ['AI', 'ê¸°ìˆ ', 'í˜ì‹ ', 'ì•±', 'ë°ì´í„°', 'ì „ì', 'ìŠ¤ë§ˆíŠ¸', 'ë””ì§€í„¸'],
            'íŒ¨ì…˜ë·°í‹°': ['ìŠ¤íƒ€ì¼', 'íŒ¨ì…˜', 'ì˜·', 'ë·°í‹°', 'í™”ì¥', 'í”¼ë¶€'],
            'ì‹í’ˆìŒë£Œ': ['ë§›', 'ë¨¹', 'ìŒì‹', 'ì»¤í”¼', 'ìˆ ', 'ìŒë£Œ', 'ì‹í’ˆ'],
            'ê±´ê°•ì˜ë£Œ': ['ê±´ê°•', 'ì˜ë£Œ', 'ì¹˜ë£Œ', 'ì•½', 'ë³‘ì›', 'ìš´ë™', 'ë‹¤ì´ì–´íŠ¸'],
            'ê¸ˆìœµì„œë¹„ìŠ¤': ['ì€í–‰', 'ì¹´ë“œ', 'ë³´í—˜', 'ê¸ˆìœµ', 'íˆ¬ì', 'ì ë¦½'],
            'ì—¬í–‰ë ˆì €': ['ì—¬í–‰', 'íœ´ê°€', 'ë ˆì €', 'ê´€ê´‘', 'í˜¸í…”', 'í•­ê³µ'],
            'ìë™ì°¨': ['ì°¨', 'ìë™ì°¨', 'ìš´ì „', 'ì—”ì§„', 'ì£¼í–‰'],
            'ê°€ì „í™ˆ': ['ê°€ì „', 'ì§‘', 'í™ˆ', 'ê°€êµ¬', 'ìƒí™œ', 'ì²­ì†Œ']
        }

    def load_sentiment_dict(self, filepath):
        """ê°ì„±ì‚¬ì „ ë¡œë“œ"""
        if not os.path.exists(filepath):
            print(f"âš ï¸  ê°ì„±ì‚¬ì „ íŒŒì¼({filepath})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ê°ì„± ë¶„ì„ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ë‹¨ì–´: ê·¹ì„± ë§¤í•‘
            for item in data:
                word = item['word']
                polarity = int(item['polarity'])
                self.sentiment_dict[word] = polarity

            print(f"âœ… ê°ì„±ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {len(self.sentiment_dict):,}ê°œ ë‹¨ì–´")
        except Exception as e:
            print(f"âš ï¸  ê°ì„±ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def extract_words(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€, ì˜ì–´)"""
        return re.findall(r'[ê°€-í£]+|[a-zA-Z]+', text)

    def classify_ad_style(self, text: str) -> List[Tuple[str, int]]:
        """ê´‘ê³  ìŠ¤íƒ€ì¼ ìë™ ë¶„ë¥˜"""
        style_scores = {}

        for style, keywords in self.style_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                style_scores[style] = score

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_styles = sorted(style_scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_styles if sorted_styles else [('ê¸°íƒ€', 0)]

    def classify_industry(self, text: str) -> List[Tuple[str, int]]:
        """ì‚°ì—…êµ° ìë™ ë¶„ë¥˜"""
        industry_scores = {}

        for industry, keywords in self.industry_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                industry_scores[industry] = score

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_industries = sorted(industry_scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_industries if sorted_industries else [('ê¸°íƒ€', 0)]

    def extract_keywords(self, words: List[str], top_n: int = 5) -> List[Tuple[str, int]]:
        """ê°ì„± í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keyword_scores = {}

        for word in words:
            if word in self.sentiment_dict and len(word) >= 2:
                score = abs(self.sentiment_dict[word])
                if score >= 1:  # ê·¹ì„±ì´ ê°•í•œ ë‹¨ì–´ë§Œ
                    keyword_scores[word] = self.sentiment_dict[word]

        # ê·¹ì„± ê°•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: abs(x[1]), reverse=True)
        return sorted_keywords[:top_n]

    def analyze_language_pattern(self, text: str) -> Dict:
        """ì–¸ì–´ íŒ¨í„´ ë¶„ì„"""
        return {
            'length': len(text),
            'word_count': len(re.findall(r'[ê°€-í£]+', text)),
            'has_question': '?' in text,
            'has_exclamation': '!' in text,
            'has_emoji': bool(re.search(r'[ã…‹ã…ğŸ˜€-ğŸ™]+', text)),
            'sentence_count': len(re.split(r'[.!?]', text.strip()))
        }

    def detect_sentiment_conflict(self, positive_words: List[Tuple], negative_words: List[Tuple]) -> Dict:
        """ê°ì„± ì¶©ëŒ ê°ì§€ ë° ë¶„ì„"""
        pos_count = len(positive_words)
        neg_count = len(negative_words)

        # ê¸ì •ì–´/ë¶€ì •ì–´ ê°•ë„ í•©ê³„
        pos_strength = sum(abs(score) for _, score in positive_words)
        neg_strength = sum(abs(score) for _, score in negative_words)

        has_conflict = pos_count >= 1 and neg_count >= 1

        conflict_type = None
        if has_conflict:
            # ì–‘ìª½ ë‹¤ ê°•í•˜ë©´ ì§„ì§œ í˜¼í•©
            if pos_count >= 2 and neg_count >= 2:
                conflict_type = "ê°•í•œí˜¼í•©"
            elif pos_strength > neg_strength * 1.5:
                conflict_type = "ê¸ì •ìš°ì„¸í˜¼í•©"
            elif neg_strength > pos_strength * 1.5:
                conflict_type = "ë¶€ì •ìš°ì„¸í˜¼í•©"
            else:
                conflict_type = "ê· í˜•í˜¼í•©"

        return {
            'has_conflict': has_conflict,
            'conflict_type': conflict_type,
            'positive_strength': pos_strength,
            'negative_strength': neg_strength
        }

    def analyze_text(self, text: str) -> Dict:
        """
        ì¢…í•© í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„
        """
        if not self.sentiment_dict:
            return None

        # ë‹¨ì–´ ì¶”ì¶œ
        words = self.extract_words(text)

        scores = []
        positive_words = []
        negative_words = []
        neutral_count = 0

        for word in words:
            if word in self.sentiment_dict:
                score = self.sentiment_dict[word]
                scores.append(score)

                if score >= 1:
                    positive_words.append((word, score))
                elif score <= -1:
                    negative_words.append((word, score))
                else:
                    neutral_count += 1

        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        avg_score = sum(scores) / len(scores) if scores else 0

        # ê°ì„± ì¶©ëŒ ê°ì§€
        conflict_info = self.detect_sentiment_conflict(positive_words, negative_words)

        # ê°ì„± ë¼ë²¨ (í˜¼í•© ê°ì„± ê³ ë ¤)
        if conflict_info['has_conflict']:
            conflict_type = conflict_info['conflict_type']

            if conflict_type == "ê°•í•œí˜¼í•©":
                label = "í˜¼í•©(ì–‘ë¦½)"
            elif conflict_type == "ê¸ì •ìš°ì„¸í˜¼í•©":
                label = "í˜¼í•©(ê¸ì •ìš°ì„¸)"
            elif conflict_type == "ë¶€ì •ìš°ì„¸í˜¼í•©":
                label = "í˜¼í•©(ë¶€ì •ìš°ì„¸)"
            else:
                label = "í˜¼í•©(ê· í˜•)"
        else:
            # ê¸°ì¡´ ë‹¨ì¼ ê°ì„± ë¼ë²¨
            if avg_score >= 1.5:
                label = "ë§¤ìš° ê¸ì •"
            elif avg_score >= 0.5:
                label = "ê¸ì •"
            elif avg_score <= -1.5:
                label = "ë§¤ìš° ë¶€ì •"
            elif avg_score <= -0.5:
                label = "ë¶€ì •"
            else:
                label = "ì¤‘ë¦½"

        return {
            'score': round(avg_score, 2),
            'sentiment_label': label,
            'positive_words': positive_words,
            'negative_words': negative_words,
            'neutral_count': neutral_count,
            'total_sentiment_words': len(scores),
            'ad_styles': self.classify_ad_style(text),
            'industries': self.classify_industry(text),
            'keywords': self.extract_keywords(words),
            'language_pattern': self.analyze_language_pattern(text),
            'sentiment_conflict': conflict_info,
            'words': words[:10]  # ì²˜ìŒ 10ê°œ ë‹¨ì–´ë§Œ ì €ì¥
        }


class AdPreferenceGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("ğŸ¯ AI ê´‘ê³  ì·¨í–¥ ë¶„ì„ê¸° v4.0 GUI")
        self.root.geometry("1000x700")

        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìœ ì—°í•œ ê²½ë¡œ íƒìƒ‰)
        script_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(script_dir)

        # ad_data.json ê²½ë¡œ ì°¾ê¸°: 1ìˆœìœ„ í˜„ì¬ ë””ë ‰í† ë¦¬, 2ìˆœìœ„ ../script/
        data_paths = [
            os.path.join(script_dir, "ad_data.json"),
            os.path.join(parent_dir, "script", "ad_data.json")
        ]
        self.data_file = data_paths[0] if os.path.exists(data_paths[0]) else data_paths[1]

        # ad_copy_database.json ê²½ë¡œ ì°¾ê¸°: 1ìˆœìœ„ í˜„ì¬ ë””ë ‰í† ë¦¬, 2ìˆœìœ„ ../script/
        db_paths = [
            os.path.join(script_dir, "ad_copy_database.json"),
            os.path.join(parent_dir, "script", "ad_copy_database.json")
        ]
        self.ad_copy_db_file = db_paths[0] if os.path.exists(db_paths[0]) else db_paths[1]

        # ë°ì´í„° ë¡œë“œ
        self.ads = self.load_data()
        self.ad_copy_database = self.load_ad_copy_database()

        # ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™”
        print("ğŸš€ AI ê´‘ê³  ì·¨í–¥ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        self.sentiment_analyzer = AdvancedSentimentAnalyzer()

        # UI êµ¬ì„±
        self.setup_ui()

    def load_data(self):
        """ì €ì¥ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
        if os.path.exists(self.data_file):
            try:
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []

    def load_ad_copy_database(self):
        """ê´‘ê³  ì¹´í”¼ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        if os.path.exists(self.ad_copy_db_file):
            try:
                with open(self.ad_copy_db_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                print(f"âœ… ê´‘ê³  ì¹´í”¼ DB ë¡œë“œ: {len(data)}ê°œ")
                return data
            except Exception as e:
                print(f"âš ï¸ ê´‘ê³  ì¹´í”¼ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                return []
        else:
            print("âš ï¸ ê´‘ê³  ì¹´í”¼ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

    def save_data(self):
        """ë°ì´í„° ì €ì¥í•˜ê¸°"""
        with open(self.data_file, 'w', encoding='utf-8') as f:
            json.dump(self.ads, f, ensure_ascii=False, indent=2)

    def setup_ui(self):
        """UI êµ¬ì„±"""
        # ìŠ¤íƒ€ì¼ ì„¤ì •
        style = ttk.Style()
        style.theme_use('clam')

        # ë©”ì¸ í”„ë ˆì„
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ìƒë‹¨ ì •ë³´ í‘œì‹œ
        info_frame = ttk.LabelFrame(main_frame, text="ğŸ“Š í†µê³„", padding="10")
        info_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)

        self.stats_label = ttk.Label(info_frame, text=f"í‰ê°€í•œ ê´‘ê³ : {len(self.ads)}ê°œ", font=('Arial', 10, 'bold'))
        self.stats_label.pack()

        # íƒ­ ì»¨íŠ¸ë¡¤
        self.notebook = ttk.Notebook(main_frame)
        self.notebook.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=10)

        # íƒ­ ìƒì„±
        self.create_rate_tab()
        self.create_analysis_tab()
        self.create_history_tab()
        self.create_recommend_tab()

        # ê·¸ë¦¬ë“œ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(1, weight=1)

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.update_stats()

    def create_rate_tab(self):
        """ê´‘ê³  í‰ê°€ íƒ­"""
        tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(tab, text="ğŸ“ ê´‘ê³  í‰ê°€í•˜ê¸°")

        # ê´‘ê³  ì…ë ¥
        ttk.Label(tab, text="ê´‘ê³  ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", font=('Arial', 11, 'bold')).grid(row=0, column=0, sticky=tk.W, pady=5)

        self.ad_text_input = scrolledtext.ScrolledText(tab, width=80, height=5, font=('Arial', 10))
        self.ad_text_input.grid(row=1, column=0, pady=5, sticky=(tk.W, tk.E))

        # ë¶„ì„ ë²„íŠ¼
        analyze_btn = ttk.Button(tab, text="ğŸ¤– AI ë¶„ì„í•˜ê¸°", command=self.analyze_ad)
        analyze_btn.grid(row=2, column=0, pady=10)

        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì˜ì—­
        result_frame = ttk.LabelFrame(tab, text="ğŸ” ë¶„ì„ ê²°ê³¼", padding="10")
        result_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=10)

        self.analysis_result = scrolledtext.ScrolledText(result_frame, width=80, height=15, font=('Arial', 9))
        self.analysis_result.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # í‰ê°€ ì…ë ¥ í”„ë ˆì„
        rating_frame = ttk.LabelFrame(tab, text="â­ í‰ê°€í•˜ê¸°", padding="10")
        rating_frame.grid(row=4, column=0, sticky=(tk.W, tk.E), pady=10)

        ttk.Label(rating_frame, text="ì´ ê´‘ê³ ê°€ ë§ˆìŒì— ë“œë‚˜ìš”? (1-10):").grid(row=0, column=0, padx=5)
        self.rating_var = tk.IntVar(value=5)
        rating_scale = ttk.Scale(rating_frame, from_=1, to=10, variable=self.rating_var, orient=tk.HORIZONTAL, length=300)
        rating_scale.grid(row=0, column=1, padx=5)

        self.rating_label = ttk.Label(rating_frame, text="5", font=('Arial', 12, 'bold'))
        self.rating_label.grid(row=0, column=2, padx=5)

        # ìŠ¤ì¼€ì¼ ê°’ ë³€ê²½ ì‹œ ë ˆì´ë¸” ì—…ë°ì´íŠ¸
        rating_scale.config(command=lambda v: self.rating_label.config(text=str(int(float(v)))))

        # ì €ì¥ ë²„íŠ¼
        save_btn = ttk.Button(rating_frame, text="ğŸ’¾ í‰ê°€ ì €ì¥í•˜ê¸°", command=self.save_rating)
        save_btn.grid(row=1, column=0, columnspan=3, pady=10)

        # ê·¸ë¦¬ë“œ ê°€ì¤‘ì¹˜
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(3, weight=1)
        result_frame.columnconfigure(0, weight=1)
        result_frame.rowconfigure(0, weight=1)

    def create_analysis_tab(self):
        """ì·¨í–¥ ë¶„ì„ íƒ­"""
        tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(tab, text="ğŸ§  AI ì·¨í–¥ ë¶„ì„")

        # ë¶„ì„ ë²„íŠ¼
        analyze_btn = ttk.Button(tab, text="ğŸ”„ ì·¨í–¥ ë¶„ì„ ìƒˆë¡œê³ ì¹¨", command=self.show_preference_analysis)
        analyze_btn.grid(row=0, column=0, pady=10)

        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì˜ì—­
        self.analysis_text = scrolledtext.ScrolledText(tab, width=100, height=35, font=('Arial', 10))
        self.analysis_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ê·¸ë¦¬ë“œ ê°€ì¤‘ì¹˜
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(1, weight=1)

    def create_history_tab(self):
        """í‰ê°€ ê¸°ë¡ íƒ­"""
        tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(tab, text="ğŸ“‹ í‰ê°€ ê¸°ë¡")

        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        refresh_btn = ttk.Button(tab, text="ğŸ”„ ê¸°ë¡ ìƒˆë¡œê³ ì¹¨", command=self.show_history)
        refresh_btn.grid(row=0, column=0, pady=10)

        # íŠ¸ë¦¬ë·°ë¡œ ê¸°ë¡ í‘œì‹œ
        columns = ('No.', 'ê´‘ê³  ë¬¸êµ¬', 'í‰ì ', 'ê°ì„±')
        self.history_tree = ttk.Treeview(tab, columns=columns, show='headings', height=25)

        self.history_tree.heading('No.', text='No.')
        self.history_tree.heading('ê´‘ê³  ë¬¸êµ¬', text='ê´‘ê³  ë¬¸êµ¬')
        self.history_tree.heading('í‰ì ', text='í‰ì ')
        self.history_tree.heading('ê°ì„±', text='ê°ì„±')

        self.history_tree.column('No.', width=50, anchor=tk.CENTER)
        self.history_tree.column('ê´‘ê³  ë¬¸êµ¬', width=600, anchor=tk.W)
        self.history_tree.column('í‰ì ', width=80, anchor=tk.CENTER)
        self.history_tree.column('ê°ì„±', width=120, anchor=tk.CENTER)

        self.history_tree.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ìŠ¤í¬ë¡¤ë°”
        scrollbar = ttk.Scrollbar(tab, orient=tk.VERTICAL, command=self.history_tree.yview)
        scrollbar.grid(row=1, column=1, sticky=(tk.N, tk.S))
        self.history_tree.configure(yscrollcommand=scrollbar.set)

        # ê·¸ë¦¬ë“œ ê°€ì¤‘ì¹˜
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(1, weight=1)

    def create_recommend_tab(self):
        """ê´‘ê³  ì¹´í”¼ ì¶”ì²œ íƒ­"""
        tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(tab, text="âœ¨ ë§ì¶¤ ê´‘ê³  ì¶”ì²œ")

        # ì¶”ì²œ ë²„íŠ¼
        recommend_btn = ttk.Button(tab, text="ğŸ¯ ë‚˜ì—ê²Œ ë§ëŠ” ê´‘ê³  ì¹´í”¼ ì¶”ì²œë°›ê¸°", command=self.show_recommendations)
        recommend_btn.grid(row=0, column=0, pady=10)

        # ì¶”ì²œ ê²°ê³¼ í‘œì‹œ ì˜ì—­
        self.recommend_text = scrolledtext.ScrolledText(tab, width=100, height=35, font=('Arial', 10))
        self.recommend_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ê·¸ë¦¬ë“œ ê°€ì¤‘ì¹˜
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(1, weight=1)

    def analyze_ad(self):
        """ê´‘ê³  ë¶„ì„ ì‹¤í–‰"""
        ad_text = self.ad_text_input.get("1.0", tk.END).strip()

        if not ad_text:
            messagebox.showwarning("ì…ë ¥ ì˜¤ë¥˜", "ê´‘ê³  ë¬¸êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return

        # ë¶„ì„ ì‹¤í–‰
        self.analysis_result.delete("1.0", tk.END)
        self.analysis_result.insert(tk.END, "ğŸ¤– AI ìë™ ë¶„ì„ ì¤‘...\n\n")
        self.root.update()

        sentiment_result = self.sentiment_analyzer.analyze_text(ad_text)

        if sentiment_result:
            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            result_text = self.format_analysis_result(sentiment_result)
            self.analysis_result.delete("1.0", tk.END)
            self.analysis_result.insert(tk.END, result_text)

            # í˜„ì¬ ë¶„ì„ ê²°ê³¼ ì €ì¥ (ë‚˜ì¤‘ì— í‰ê°€ ì €ì¥ ì‹œ ì‚¬ìš©)
            self.current_sentiment = sentiment_result
        else:
            self.analysis_result.delete("1.0", tk.END)
            self.analysis_result.insert(tk.END, "âš ï¸ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def format_analysis_result(self, analysis: Dict) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        result = "=" * 70 + "\n"
        result += "ğŸ“Š AI ê°ì„± ë¶„ì„ ê²°ê³¼\n"
        result += "=" * 70 + "\n\n"

        # ê°ì„± ì ìˆ˜
        score = analysis['score']
        result += f"ê°ì„± ë¼ë²¨: [{analysis['sentiment_label']}]\n"
        result += f"ê°ì„± ì ìˆ˜: {score}\n\n"

        # ì£¼ìš” ë‹¨ì–´
        if analysis.get('words'):
            words_str = ', '.join(analysis['words'][:8])
            result += f"ì£¼ìš” ë‹¨ì–´: {words_str}\n\n"

        # í˜¼í•© ê°ì„± ì •ë³´
        if analysis.get('sentiment_conflict', {}).get('has_conflict'):
            conflict = analysis['sentiment_conflict']
            pos_words = [w[0] for w in analysis['positive_words'][:3]]
            neg_words = [w[0] for w in analysis['negative_words'][:3]]

            result += "âš¡ ê°ì„± ì¶©ëŒ ê°ì§€!\n"
            result += f"  ê¸ì •ì–´: {', '.join(pos_words)} (ê°•ë„: {conflict['positive_strength']:.1f})\n"
            result += f"  ë¶€ì •ì–´: {', '.join(neg_words)} (ê°•ë„: {conflict['negative_strength']:.1f})\n\n"

            if conflict['conflict_type'] == "ê°•í•œí˜¼í•©":
                result += "  ğŸ’¡ ìŠ¤í† ë¦¬í…”ë§í˜•/ì—­ì„¤í˜• ê´‘ê³ ë¡œ ì¶”ì •ë©ë‹ˆë‹¤\n\n"

        # ê´‘ê³  ìŠ¤íƒ€ì¼
        if analysis['ad_styles']:
            styles = ', '.join([f"{s[0]}({s[1]}ì )" for s in analysis['ad_styles'][:3]])
            result += f"ğŸ¨ ê´‘ê³  ìŠ¤íƒ€ì¼: {styles}\n\n"

        # ì‚°ì—…êµ°
        if analysis.get('industries'):
            industries = ', '.join([f"{i[0]}({i[1]}ì )" for i in analysis['industries'][:3]])
            result += f"ğŸ¢ ì‚°ì—…êµ°: {industries}\n\n"

        # í•µì‹¬ í‚¤ì›Œë“œ
        if analysis['keywords']:
            keywords = ', '.join([f"'{k[0]}'({k[1]})" for k in analysis['keywords'][:5]])
            result += f"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: {keywords}\n\n"

        # ì–¸ì–´ íŒ¨í„´
        pattern = analysis['language_pattern']
        features = []
        if pattern['has_exclamation']:
            features.append("ê°•ì¡°í˜•")
        if pattern['has_question']:
            features.append("ì§ˆë¬¸í˜•")
        if pattern['length'] < 20:
            features.append("ì§§ê³  ì„íŒ©íŠ¸")
        elif pattern['length'] > 50:
            features.append("ìƒì„¸ ì„¤ëª…í˜•")

        if features:
            result += f"ğŸ’¬ í‘œí˜„ íŠ¹ì§•: {', '.join(features)}\n"

        result += "\n" + "=" * 70

        return result

    def save_rating(self):
        """í‰ê°€ ì €ì¥"""
        ad_text = self.ad_text_input.get("1.0", tk.END).strip()

        if not ad_text:
            messagebox.showwarning("ì…ë ¥ ì˜¤ë¥˜", "ê´‘ê³  ë¬¸êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return

        rating = self.rating_var.get()

        # ê°ì„± ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        sentiment_result = getattr(self, 'current_sentiment', None)
        if not sentiment_result:
            # ë¶„ì„ì´ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë¶„ì„
            sentiment_result = self.sentiment_analyzer.analyze_text(ad_text)

        # ë°ì´í„° ì €ì¥
        ad_info = {
            "ad_text": ad_text,
            "overall_rating": rating,
            "sentiment_analysis": sentiment_result,
            "timestamp": datetime.now().isoformat()
        }

        self.ads.append(ad_info)
        self.save_data()

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.update_stats()

        # ì„±ê³µ ë©”ì‹œì§€
        messagebox.showinfo("ì €ì¥ ì™„ë£Œ", f"âœ… ê´‘ê³  í‰ê°€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\ní‰ì : {rating}/10")

        # ì…ë ¥ ì´ˆê¸°í™”
        self.ad_text_input.delete("1.0", tk.END)
        self.analysis_result.delete("1.0", tk.END)
        self.rating_var.set(5)
        self.current_sentiment = None

    def update_stats(self):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        num_ads = len(self.ads)
        if num_ads > 0:
            avg_rating = sum(ad["overall_rating"] for ad in self.ads) / num_ads
            self.stats_label.config(text=f"í‰ê°€í•œ ê´‘ê³ : {num_ads}ê°œ | í‰ê·  ë§Œì¡±ë„: {avg_rating:.1f}/10ì ")
        else:
            self.stats_label.config(text=f"í‰ê°€í•œ ê´‘ê³ : {num_ads}ê°œ")

    def show_preference_analysis(self):
        """ì·¨í–¥ ë¶„ì„ í‘œì‹œ"""
        self.analysis_text.delete("1.0", tk.END)

        if not self.ads:
            self.analysis_text.insert(tk.END, "ì•„ì§ í‰ê°€í•œ ê´‘ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.\nê´‘ê³ ë¥¼ í‰ê°€í•˜ê³  ë‚˜ë§Œì˜ ì·¨í–¥ í”„ë¡œí•„ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!")
            return

        result = "=" * 80 + "\n"
        result += "ğŸ§  AI ê¸°ë°˜ ê´‘ê³  ì·¨í–¥ ë¶„ì„ ë¦¬í¬íŠ¸\n"
        result += "=" * 80 + "\n\n"

        num_ads = len(self.ads)
        avg_rating = sum(ad["overall_rating"] for ad in self.ads) / num_ads

        result += f"ğŸ“ˆ í‰ê°€ ë°ì´í„°: {num_ads}ê°œ ê´‘ê³  | í‰ê·  ë§Œì¡±ë„: {avg_rating:.1f}/10ì \n"
        result += "-" * 80 + "\n\n"

        # ê°ì„± ë¶„ì„ì´ ìˆëŠ” ê´‘ê³ ë§Œ ì¶”ì¶œ
        ads_with_sentiment = [ad for ad in self.ads if ad.get("sentiment_analysis")]

        if ads_with_sentiment:
            # ê°ì„± í†¤ ì„ í˜¸ë„
            result += "ğŸ­ ê°ì„± í†¤ ì„ í˜¸ë„\n"
            result += "-" * 80 + "\n"

            sentiment_ratings = {}
            for ad in ads_with_sentiment:
                label = ad["sentiment_analysis"]["sentiment_label"]
                rating = ad["overall_rating"]

                if label not in sentiment_ratings:
                    sentiment_ratings[label] = []
                sentiment_ratings[label].append(rating)

            sorted_sentiments = sorted(
                sentiment_ratings.items(),
                key=lambda x: sum(x[1])/len(x[1]),
                reverse=True
            )

            for label, ratings in sorted_sentiments[:5]:
                avg = sum(ratings) / len(ratings)
                result += f"  {label:15s} | í‰ê· : {avg:4.1f}ì  | í‰ê°€ ìˆ˜: {len(ratings):3d}ê°œ\n"

            if sorted_sentiments:
                best_sentiment = sorted_sentiments[0][0]
                result += f"\nğŸ’¡ ë‹¹ì‹ ì€ '{best_sentiment}' í†¤ì˜ ê´‘ê³ ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.\n\n"

            # ê´‘ê³  ìŠ¤íƒ€ì¼ ì„ í˜¸ë„
            result += "ğŸ¨ ê´‘ê³  ìŠ¤íƒ€ì¼ ì„ í˜¸ë„\n"
            result += "-" * 80 + "\n"

            style_ratings = {}
            for ad in ads_with_sentiment:
                if ad["sentiment_analysis"].get("ad_styles"):
                    main_style = ad["sentiment_analysis"]["ad_styles"][0][0]
                    rating = ad["overall_rating"]

                    if main_style not in style_ratings:
                        style_ratings[main_style] = []
                    style_ratings[main_style].append(rating)

            if style_ratings:
                sorted_styles = sorted(
                    style_ratings.items(),
                    key=lambda x: sum(x[1])/len(x[1]),
                    reverse=True
                )

                for style, ratings in sorted_styles[:5]:
                    avg = sum(ratings) / len(ratings)
                    result += f"  {style:15s} | í‰ê· : {avg:4.1f}ì  | í‰ê°€ ìˆ˜: {len(ratings):3d}ê°œ\n"

                best_style = sorted_styles[0][0]
                result += f"\nğŸ’¡ ë‹¹ì‹ ì€ '{best_style}' ê´‘ê³ ë¥¼ ê°€ì¥ ì¢‹ì•„í•©ë‹ˆë‹¤.\n\n"

        # ìµœê³ /ìµœì € ê´‘ê³ 
        result += "â­ ë² ìŠ¤íŠ¸ & ì›ŒìŠ¤íŠ¸\n"
        result += "-" * 80 + "\n"

        sorted_ads = sorted(self.ads, key=lambda x: x["overall_rating"], reverse=True)

        best_ad = sorted_ads[0]
        result += f"\nğŸ† ê°€ì¥ ë§ˆìŒì— ë“  ê´‘ê³  ({best_ad['overall_rating']}ì ):\n"
        result += f"   \"{best_ad['ad_text'][:100]}{'...' if len(best_ad['ad_text']) > 100 else ''}\"\n"

        if len(sorted_ads) >= 3:
            worst_ad = sorted_ads[-1]
            result += f"\nğŸ‘ ì•„ì‰¬ì› ë˜ ê´‘ê³  ({worst_ad['overall_rating']}ì ):\n"
            result += f"   \"{worst_ad['ad_text'][:100]}{'...' if len(worst_ad['ad_text']) > 100 else ''}\"\n"

        self.analysis_text.insert(tk.END, result)

    def show_history(self):
        """í‰ê°€ ê¸°ë¡ í‘œì‹œ"""
        # ê¸°ì¡´ í•­ëª© ì œê±°
        for item in self.history_tree.get_children():
            self.history_tree.delete(item)

        if not self.ads:
            return

        # ë°ì´í„° ì¶”ê°€
        for i, ad in enumerate(self.ads, 1):
            ad_text = ad['ad_text'][:60] + "..." if len(ad['ad_text']) > 60 else ad['ad_text']
            rating = f"{ad['overall_rating']}/10"

            sentiment = "N/A"
            if ad.get("sentiment_analysis"):
                sentiment = ad["sentiment_analysis"]["sentiment_label"]

            self.history_tree.insert('', tk.END, values=(i, ad_text, rating, sentiment))

    def show_recommendations(self):
        """ë§ì¶¤ ê´‘ê³  ì¶”ì²œ í‘œì‹œ"""
        self.recommend_text.delete("1.0", tk.END)

        if not self.ad_copy_database:
            self.recommend_text.insert(tk.END, "ê´‘ê³  ì¹´í”¼ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return

        if len(self.ads) < 3:
            self.recommend_text.insert(tk.END, "ì¶”ì²œì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ê°œ ì´ìƒì˜ ê´‘ê³ ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.")
            return

        self.recommend_text.insert(tk.END, "ğŸ¤– ì·¨í–¥ ë¶„ì„ ì¤‘...\n\n")
        self.root.update()

        recommendations = self.recommend_personalized_copies(top_n=10)

        if not recommendations:
            self.recommend_text.delete("1.0", tk.END)
            self.recommend_text.insert(tk.END, "ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ê´‘ê³  ì¹´í”¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì¶”ì²œ ê²°ê³¼ í¬ë§·íŒ…
        result = "=" * 80 + "\n"
        result += "âœ¨ AI ë§ì¶¤ ê´‘ê³  ì¹´í”¼ ì¶”ì²œ\n"
        result += "=" * 80 + "\n\n"

        high_rated_count = len([ad for ad in self.ads if ad['overall_rating'] >= 7])
        result += f"ğŸ“Š ë¶„ì„ ê¸°ë°˜: ë†’ì€ í‰ê°€ ê´‘ê³  {high_rated_count}ê°œ\n"
        result += "-" * 80 + "\n\n"

        for idx, (copy_data, similarity, reason) in enumerate(recommendations, 1):
            result += f"{idx}. [{copy_data.get('category', 'N/A')}] {copy_data['text']}\n"
            result += f"   ë¸Œëœë“œ: {copy_data.get('brand', 'N/A')} | ìœ ì‚¬ë„: {similarity:.2f}\n\n"

        # ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶„ì„
        category_count = {}
        for copy_data, _, _ in recommendations:
            category = copy_data.get('category', 'ê¸°íƒ€')
            category_count[category] = category_count.get(category, 0) + 1

        if category_count:
            top_category = max(category_count.items(), key=lambda x: x[1])
            result += f"ğŸ’¡ ë‹¹ì‹ ì€ '{top_category[0]}' ìŠ¤íƒ€ì¼ ê´‘ê³ ë¥¼ ì„ í˜¸í•˜ì‹œëŠ” ê²ƒ ê°™ì•„ìš”! ({top_category[1]}ê°œ)\n\n"

        if len(category_count) > 1:
            result += f"ì¹´í…Œê³ ë¦¬ ë¶„í¬: {', '.join([f'{k}({v})' for k, v in sorted(category_count.items(), key=lambda x: x[1], reverse=True)])}\n"

        self.recommend_text.delete("1.0", tk.END)
        self.recommend_text.insert(tk.END, result)

    def recommend_personalized_copies(self, top_n: int = 10) -> List[Tuple[Dict, float, str]]:
        """ì‚¬ìš©ì ì·¨í–¥ ê¸°ë°˜ ê´‘ê³  ì¹´í”¼ ì¶”ì²œ"""
        if not self.ad_copy_database:
            return []

        if len(self.ads) < 3:
            return []

        # ë†’ì€ í‰ê°€ë¥¼ ë°›ì€ ê´‘ê³  (7ì  ì´ìƒ)
        high_rated_ads = [ad for ad in self.ads if ad['overall_rating'] >= 7]

        if not high_rated_ads:
            return []

        try:
            # ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” ê´‘ê³  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            user_liked_texts = [ad['ad_text'] for ad in high_rated_ads]

            # ê´‘ê³  ì¹´í”¼ DB í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            db_texts = [copy['text'] for copy in self.ad_copy_database]

            # ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            all_texts = user_liked_texts + db_texts

            # TF-IDF ë²¡í„°í™”
            vectorizer = TfidfVectorizer()
            tfidf_matrix = vectorizer.fit_transform(all_texts)

            # ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” ê´‘ê³ ë“¤ì˜ í‰ê·  ë²¡í„° ê³„ì‚°
            user_vectors = tfidf_matrix[:len(user_liked_texts)]
            user_profile = np.asarray(user_vectors.mean(axis=0))

            # DB ê´‘ê³ ë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            db_vectors = tfidf_matrix[len(user_liked_texts):]
            similarities = cosine_similarity(user_profile, db_vectors)[0]

            # ìœ ì‚¬ë„ê°€ 0.1 ì´ìƒì¸ ê²ƒë§Œ í•„í„°ë§
            valid_indices = [i for i, sim in enumerate(similarities) if sim >= 0.1]

            if not valid_indices:
                return []

            # ìƒìœ„ Nê°œ ì¶”ì²œ
            top_indices = sorted(valid_indices, key=lambda i: similarities[i], reverse=True)[:top_n]

            # ê²°ê³¼ êµ¬ì„±
            recommendations = []
            for idx in top_indices:
                copy_data = self.ad_copy_database[idx]
                similarity = similarities[idx]
                reason = f"{copy_data.get('category', 'ê¸°íƒ€')} ìŠ¤íƒ€ì¼"
                recommendations.append((copy_data, similarity, reason))

            return recommendations

        except Exception as e:
            print(f"âš ï¸ ì¶”ì²œ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            return []


def main():
    root = tk.Tk()
    app = AdPreferenceGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()
